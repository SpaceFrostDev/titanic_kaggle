{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11315861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3294bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Prints the column names and their unique values.\"\"\"\n",
    "    if isinstance(df, pd.core.series.Series):\n",
    "        print(f\"{df.unique()}\")\n",
    "    elif isinstance(df, pd.core.frame.DataFrame):\n",
    "        for col in df:\n",
    "            print(f\"{col}: {df[col].unique()}\")\n",
    "    else:\n",
    "        raise TypeError(f\"Expected DataFrame or Series, recieved {type(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768af74b",
   "metadata": {},
   "source": [
    "# Peep the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6b4991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(Path('./data/train.csv'))\n",
    "display(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261eea6c",
   "metadata": {},
   "source": [
    "# Drop irrelevant columns and deal with NaNs\n",
    "Use correlation, the number of unique values and common sense to decide irrelevance. For example, `PassangerId` which is simply counting up is assumed to have no impact on passanger mortality. `Name` most likely won't be relevant since all the information it conveys, like marriage status, or socio-economic status (Dr. or Master) are accounted for in other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3f7dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "0           0       3    male  22.0      1      0   7.2500   NaN        S\n",
       "1           1       1  female  38.0      1      0  71.2833   C85        C\n",
       "2           1       3  female  26.0      0      0   7.9250   NaN        S\n",
       "3           1       1  female  35.0      1      0  53.1000  C123        S\n",
       "4           0       3    male  35.0      0      0   8.0500   NaN        S\n",
       "..        ...     ...     ...   ...    ...    ...      ...   ...      ...\n",
       "886         0       2    male  27.0      0      0  13.0000   NaN        S\n",
       "887         1       1  female  19.0      0      0  30.0000   B42        S\n",
       "888         0       3  female   NaN      1      2  23.4500   NaN        S\n",
       "889         1       1    male  26.0      0      0  30.0000  C148        C\n",
       "890         0       3    male  32.0      0      0   7.7500   NaN        Q\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I'll drop the 'Ticket' and 'PassengerId' columns for now, as I suspect they have no bearing on survival\n",
    "cleaned_df = raw_df.drop(columns=['PassengerId', 'Ticket', 'Name'])\n",
    "display(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd22203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see a few NaNs\n",
    "def count_nans(df: pd.DataFrame) -> None:\n",
    "    \"Prints a count of the occurences of NaNs in each column\"\n",
    "    for col in df.columns:\n",
    "        print(f\"{col} NaNs: {df[col].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba23d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived NaNs: 0\n",
      "Pclass NaNs: 0\n",
      "Sex NaNs: 0\n",
      "Age NaNs: 177\n",
      "SibSp NaNs: 0\n",
      "Parch NaNs: 0\n",
      "Fare NaNs: 0\n",
      "Cabin NaNs: 687\n",
      "Embarked NaNs: 2\n"
     ]
    }
   ],
   "source": [
    "count_nans(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ac50a",
   "metadata": {},
   "source": [
    "### Note on `Cabin` variable\n",
    "It would be nice to include as, undoubtedly, a passenger's position on the ship affects their mortality in event of a major accident but, there are 687 `NaN` values. That's 687 out of 891. Too many null values to be useful, so I'll drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fa3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.drop(columns=['Cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfabe687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived NaNs: 0\n",
      "Pclass NaNs: 0\n",
      "Sex NaNs: 0\n",
      "Age NaNs: 0\n",
      "SibSp NaNs: 0\n",
      "Parch NaNs: 0\n",
      "Fare NaNs: 0\n",
      "Embarked NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "cleaned_df['Age'].fillna(cleaned_df['Age'].mean(), inplace=True)\n",
    "cleaned_df['Embarked'].fillna('UNK', inplace=True)\n",
    "count_nans(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0c9aa",
   "metadata": {},
   "source": [
    "# Encode Sex and Embarked columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13dc8605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' 'UNK']\n"
     ]
    }
   ],
   "source": [
    "print_unique(cleaned_df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41826ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch     Fare  Embarked\n",
       "0           0       3    1  22.000000      1      0   7.2500         0\n",
       "1           1       1    0  38.000000      1      0  71.2833         1\n",
       "2           1       3    0  26.000000      0      0   7.9250         0\n",
       "3           1       1    0  35.000000      1      0  53.1000         0\n",
       "4           0       3    1  35.000000      0      0   8.0500         0\n",
       "..        ...     ...  ...        ...    ...    ...      ...       ...\n",
       "886         0       2    1  27.000000      0      0  13.0000         0\n",
       "887         1       1    0  19.000000      0      0  30.0000         0\n",
       "888         0       3    0  29.699118      1      2  23.4500         0\n",
       "889         1       1    1  26.000000      0      0  30.0000         1\n",
       "890         0       3    1  32.000000      0      0   7.7500         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_df['Sex'].replace({'male': 1, 'female': 0}, inplace=True)\n",
    "cleaned_df['Embarked'].replace({'S': 0, 'C': 1, 'Q': 2, 'UNK': 3}, inplace=True)\n",
    "display(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca43e18",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "Even though the test set is withheld by Kaggle, I'm only allowed so many attempts, so I'll withhold a small chunk to iterably test hyper-parameter selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d598383",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop(columns=['Survived'])\n",
    "y = cleaned_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd39399",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bbbf3",
   "metadata": {},
   "source": [
    "# Normalizing continuous variables between 0 - 1\n",
    "Via `sklearn`'s `MinMaxScaler()`. An idea to test later would be to normalize `Age` and `Fare` using their own scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c1f8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4022ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[['Age', 'Fare']] = scaler.transform(X_train[['Age', 'Fare']])\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[['Age','Fare']] = scaler.transform(X_test[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb0fade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107816</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040062</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107816</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.509927</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170646</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258608</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "165       3    1  0.107816      0      2  0.040062         0\n",
       "541       3    0  0.107816      4      2  0.061045         0\n",
       "625       1    1  0.761247      0      0  0.063086         0\n",
       "388       3    1  0.367921      0      0  0.015086         2\n",
       "76        3    1  0.367921      0      0  0.015412         0\n",
       "..      ...  ...       ...    ...    ...       ...       ...\n",
       "106       3    0  0.258608      0      0  0.014932         0\n",
       "270       1    1  0.367921      0      0  0.060508         0\n",
       "860       3    1  0.509927      2      0  0.027538         0\n",
       "435       1    0  0.170646      1      2  0.234224         0\n",
       "102       1    1  0.258608      0      1  0.150855         0\n",
       "\n",
       "[801 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7306f7",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "724a0519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    495\n",
       "1    306\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96bc353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE()\n",
    "X_train_scaled_os, y_train_os = oversampler.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d57970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    495\n",
       "0    495\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_os.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27b21da7",
   "metadata": {},
   "source": [
    "# Tensor pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4df6924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7]),\n",
       " tensor([3.0000, 1.0000, 0.1078, 0.0000, 2.0000, 0.0401, 0.0000],\n",
       "        requires_grad=True),\n",
       " tensor(1., requires_grad=True))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_train_scaled_os.values, y_train_os)]\n",
    "validation_ds = [(torch.tensor(X_data, dtype=torch.float, requires_grad=True), torch.tensor(y_data, dtype=torch.float, requires_grad=True)) for X_data, y_data in zip(X_test_scaled.values, y_test.values)]\n",
    "\n",
    "train_ds[0][0].shape, train_ds[0][0], train_ds[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb070edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=len(train_ds) // 10, shuffle=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(validation_ds, batch_size=len(validation_ds) // 10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63d5e2",
   "metadata": {},
   "source": [
    "# Model\n",
    "A simple dense neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98665882",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neuron_count = train_ds[0][0].shape[0]\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_neuron_count, input_neuron_count // 2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(input_neuron_count // 2, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b65ee910",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = nn.BCEWithLogitsLoss()\n",
    "adam_optim = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2360",
   "metadata": {},
   "source": [
    "# My custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "152549cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm reusing my custom training loop\n",
    "def training_loop(epochs, model, loss_fcn, optimizer, train_dataloader, val_dataloader,\n",
    "                  *, save_best=True, metrics=True, logging=True):\n",
    "    \"\"\"\n",
    "    Custom training loop\n",
    "    Parameters:\n",
    "        epochs: int, number of epochs to train for\n",
    "        model: nn.Module or subclass thereof, from which to obtain predictions\n",
    "        loss_fcn: any pytorch loss function\n",
    "        optimizer: any optimizer\n",
    "        train_dataloader: PyTorch dataloader from which to pull data\n",
    "        val_dataloader: \"\n",
    "        save_best: bool, WARNING only use on smaller models, cache and serialize best model at end of training\n",
    "        metrics: bool, control calculation and printing of numbers to the screen\n",
    "        logging: bool, control printing of tensor info to screen after each step\n",
    "    Returns: \n",
    "        Trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    highest_accuracy = 0\n",
    "    cached_model = None\n",
    "    for epoch in range(epochs):\n",
    "        for features, labels in train_dataloader:\n",
    "            labels.unsqueeze_(1)\n",
    "            if logging: print_t_info([features, labels], [\"Train Feats: \", \"Train Labels: \"])\n",
    "            \n",
    "            train_predictions = model(features)\n",
    "            \n",
    "            train_loss = loss_fcn(train_predictions, labels)\n",
    "            \n",
    "            if logging: print_t_info([train_predictions, train_loss], [\"Train Preds:\", \"Train Loss:\"])\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for features, labels in val_dataloader:\n",
    "            labels.unsqueeze_(1)\n",
    "            if logging: print_t_info([features, labels], ['Val Feats: ', 'Val Labels:'])\n",
    "            \n",
    "            val_predictions = model(features)\n",
    "            \n",
    "            val_loss = loss_fcn(val_predictions, labels)\n",
    "            \n",
    "            if logging: print_t_info([val_predictions, val_loss], ['Val Preds:', 'Val Loss:'])\n",
    "            \n",
    "            \n",
    "        if metrics:\n",
    "            total += val_predictions.shape[0]\n",
    "            correct = int(((val_predictions > 0.5) == labels.type(torch.BoolTensor)).sum())\n",
    "            print(f\"Epoch {epoch:03}\\tTrain Loss: {train_loss:.4}\\tVal Loss: \"\n",
    "                  f\"{val_loss:.4}\\tAccuracy: {correct/total:%}\")\n",
    "        if save_best:\n",
    "            latest_accuracy = correct/total\n",
    "            if latest_accuracy > highest_accuracy:\n",
    "                highest_accuracy = latest_accuracy\n",
    "                cached_model = model\n",
    "                \n",
    "        if save_best:\n",
    "            model_pth = Path(f'./models/{highest_accuracy * 100}_model')\n",
    "            torch.save(cached_model, model_pth)\n",
    "            print(f\"Model saved to {model_pth}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84f66b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 001\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 002\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 003\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 004\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 005\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 006\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 007\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 008\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 009\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 010\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 011\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 012\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 013\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 014\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 015\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 016\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 017\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 018\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 019\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 020\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 021\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 022\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 023\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 024\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 025\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 026\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 027\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 028\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 029\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 030\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 031\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 032\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 033\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 034\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 035\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 036\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 037\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 038\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 039\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 040\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 041\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 042\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 043\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 044\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 045\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 046\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 047\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 048\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 049\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 050\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 051\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 052\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 053\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 054\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 055\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 056\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 057\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 058\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 059\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 060\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 061\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 062\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 063\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 064\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 065\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 066\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 067\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 068\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 069\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 070\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 071\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 072\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 073\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 074\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 075\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 076\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 077\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 078\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 079\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 080\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 081\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 082\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 083\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 084\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 085\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 086\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 087\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 088\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 089\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 090\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 091\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 092\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 093\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 094\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 095\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 096\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 097\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 098\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 099\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 100\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 101\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 102\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 103\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 104\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 105\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 106\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 107\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 108\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 109\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 110\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 111\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 112\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 113\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 114\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 115\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 116\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 117\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 118\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 119\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 120\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 121\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 122\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 123\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 124\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 125\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 126\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 127\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 128\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 129\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 130\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 131\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 132\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 133\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 134\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 135\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 137\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 138\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 139\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 140\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 141\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 142\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 143\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 144\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 145\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 146\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 147\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 148\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 149\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 150\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 151\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 152\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 153\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 154\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 155\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 156\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 157\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 158\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 159\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 160\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 161\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 162\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 163\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 164\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 165\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 166\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 167\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 168\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 169\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 170\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 171\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 172\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 173\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 174\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 175\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 176\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 177\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 178\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 179\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 180\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 181\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 182\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 183\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 184\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 185\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 186\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 187\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 188\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 189\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 190\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 191\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 192\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 193\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 194\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 195\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 196\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 197\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 198\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 199\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 200\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 201\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 202\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 203\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 204\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 205\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 206\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 207\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 208\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 209\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 210\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 211\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 212\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 213\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 214\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 215\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 216\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 217\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 218\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 219\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 220\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 221\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 222\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 223\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 224\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 225\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 226\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 227\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 228\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 229\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 230\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 231\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 232\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 233\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 234\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 235\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 236\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 237\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 238\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 239\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 240\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 241\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 242\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 243\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 244\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 245\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 246\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 247\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 248\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 249\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 250\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 251\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 252\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 253\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 254\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 255\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 256\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 257\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 258\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 259\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 260\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 261\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 262\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 263\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 264\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 265\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 266\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 267\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 268\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 269\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 270\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 271\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 272\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 273\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 275\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 276\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 277\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 278\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 279\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 280\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 281\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 282\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 283\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 284\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 285\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 286\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 287\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 288\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 289\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 290\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 291\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 292\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 293\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 294\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 295\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 296\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 297\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 298\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 299\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 300\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 301\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 302\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 303\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 304\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 305\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 306\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 307\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 308\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 309\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 310\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 311\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 312\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 313\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 314\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 315\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 316\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 317\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 318\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 319\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 320\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 321\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 322\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 323\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 324\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 325\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 326\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 327\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 328\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 329\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 330\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 331\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 332\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 333\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 334\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 335\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 336\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 337\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 338\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 339\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 340\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 341\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 342\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 343\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 344\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 345\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 346\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 347\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 348\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 349\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 350\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 351\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 352\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 353\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 354\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 355\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 356\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 357\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 358\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 359\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 360\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 361\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 362\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 363\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 364\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 365\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 366\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 367\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 368\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 369\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 370\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 371\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 372\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 373\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 374\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 375\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 376\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 377\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 378\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 379\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 380\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 381\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 382\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 383\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 384\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 385\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 386\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 387\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 388\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 389\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 390\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 391\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 392\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 393\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 394\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 395\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 396\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 397\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 398\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 399\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 400\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 401\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 402\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 403\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 404\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 405\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 406\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 407\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 408\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 409\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 410\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 411\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 413\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 414\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 415\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 416\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 417\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 418\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 419\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 420\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 421\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 422\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 423\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 424\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 425\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 426\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 427\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 428\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 429\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 430\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 431\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 432\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 433\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 434\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 435\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 436\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 437\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 438\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 439\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 440\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 441\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 442\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 443\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 444\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 445\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 446\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 447\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 448\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 449\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 450\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 451\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 452\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 453\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 454\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 455\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 456\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 457\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 458\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 459\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 460\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 461\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 462\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 463\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 464\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 465\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 466\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 467\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 468\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 469\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 470\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 471\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 472\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 473\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 474\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 475\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 476\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 477\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 478\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 479\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 480\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 481\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 482\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 483\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 484\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 485\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 486\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 487\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 488\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 489\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 490\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 491\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 492\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 493\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 494\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 495\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 496\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 497\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 498\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 499\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 500\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 501\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 502\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 503\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 504\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 505\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 506\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 507\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 508\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 509\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 510\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 511\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 512\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 513\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 514\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 515\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 516\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 517\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 518\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 519\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 520\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 521\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 522\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 523\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 524\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 525\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 526\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 527\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 528\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 529\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 530\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 531\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 532\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 533\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 534\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 535\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 536\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 537\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 538\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 539\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 540\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 541\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 542\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 543\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 544\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 545\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 546\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 547\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 548\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 549\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 551\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 552\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 553\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 554\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 555\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 556\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 557\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 558\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 559\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 560\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 561\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 562\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 563\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 564\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 565\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 566\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 567\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 568\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 569\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 570\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 571\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 572\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 573\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 574\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 575\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 576\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 577\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 578\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 579\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 580\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 581\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 582\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 583\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 584\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 585\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 586\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 587\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 588\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 589\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 590\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 591\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 592\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 593\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 594\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 595\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 596\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 597\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 598\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 599\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 600\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 601\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 602\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 603\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 604\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 605\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 606\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 607\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 608\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 609\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 610\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 611\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 612\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 613\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 614\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 615\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 616\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 617\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 618\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 619\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 620\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 621\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 622\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 623\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 624\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 625\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 626\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 627\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 628\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 629\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 630\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 631\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 632\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 633\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 634\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 635\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 636\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 637\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 638\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 639\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 640\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 641\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 642\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 643\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 644\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 645\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 646\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 647\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 648\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 649\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 650\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 651\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 652\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 653\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 654\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 655\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 656\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 657\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 658\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 659\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 660\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 661\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 662\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 663\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 664\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 665\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 666\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 667\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 668\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 669\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 670\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 671\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 672\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 673\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 674\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 675\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 676\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 677\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 678\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 679\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 680\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 681\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 682\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 683\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 684\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 685\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 686\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 687\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 688\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 689\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 690\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 691\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 692\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 693\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 694\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 695\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 696\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 697\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 698\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 699\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 700\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 701\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 702\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 703\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 704\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 705\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 706\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 707\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 708\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 709\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 710\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 711\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 712\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 713\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 714\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 715\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 716\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 717\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 718\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 719\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 720\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 721\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 722\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 723\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 724\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 725\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 726\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 727\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 728\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 729\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 730\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 731\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 732\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 733\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 734\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 735\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 736\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 737\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 738\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 739\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 740\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 741\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 742\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 743\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 744\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 745\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 746\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 747\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 748\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 749\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 750\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 751\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 752\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 753\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 754\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 755\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 756\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 757\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 758\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 759\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 760\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 761\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 762\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 763\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 764\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 765\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 766\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 767\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 768\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 769\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 770\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 771\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 772\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 773\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 774\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 775\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 776\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 777\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 778\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 779\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 780\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 781\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 782\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 783\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 784\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 785\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 786\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 787\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 788\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 789\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 790\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 791\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 792\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 793\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 794\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 795\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 796\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 797\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 798\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 799\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 800\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 801\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 802\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 803\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 804\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 805\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 806\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 807\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 808\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 809\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 810\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 811\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 812\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 813\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 814\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 815\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 816\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 817\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 818\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 819\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 820\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 821\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 822\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 823\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 824\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 825\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 827\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 828\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 829\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 830\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 831\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 832\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 833\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 834\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 835\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 836\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 837\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 838\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 839\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 840\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 841\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 842\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 843\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 844\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 845\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 846\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 847\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 848\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 849\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 850\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 851\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 852\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 853\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 854\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 855\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 856\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 857\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 858\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 859\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 860\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 861\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 862\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 863\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 864\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 865\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 866\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 867\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 868\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 869\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 870\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 871\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 872\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 873\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 874\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 875\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 876\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 877\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 878\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 879\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 880\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 881\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 882\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 883\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 884\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 885\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 886\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 887\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 888\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 889\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 890\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 891\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 892\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 893\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 894\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 895\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 896\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 897\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 898\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 899\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 900\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 901\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 902\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 903\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 904\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 905\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 906\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 907\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 908\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 909\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 910\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 911\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 912\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 913\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 914\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 915\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 916\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 917\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 918\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 919\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 920\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 921\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 922\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 923\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 924\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 925\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 926\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 927\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 928\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 929\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 930\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 931\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 932\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 933\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 934\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 935\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 936\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 937\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 938\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 939\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 940\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 941\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 942\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 943\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 944\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 945\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 946\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 947\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 948\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 949\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 950\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 951\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 952\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 953\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 954\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 955\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 956\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 957\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 958\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 959\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 960\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 961\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 962\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 963\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 964\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 965\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 966\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 967\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 968\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 969\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 970\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 971\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 972\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 973\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 974\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 975\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 976\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 977\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 978\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 979\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 980\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 981\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 982\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 983\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 984\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 985\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 986\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 987\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 988\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 989\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 990\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 991\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 992\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 993\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 994\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 995\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 996\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 997\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 998\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n",
      "Epoch 999\tTrain Loss: 0.8855\tVal Loss: 0.703\tAccuracy: 55.555556%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=7, out_features=3, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(1000, model, loss_fcn, a_optim, train_dataloader, val_dataloader, logging=False, save_best=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b63f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d973020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
